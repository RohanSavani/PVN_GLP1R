{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\n\nIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\n\nImporting the numpy C-extensions failed. This error can happen for\nmany reasons, often due to issues with your setup or how NumPy was\ninstalled.\n\nWe have compiled some common reasons and troubleshooting tips at:\n\n    https://numpy.org/devdocs/user/troubleshooting-importerror.html\n\nPlease note and check the following:\n\n  * The Python version is: Python3.10 from \"/usr/local/bin/python3\"\n  * The NumPy version is: \"1.22.0\"\n\nand make sure that they are the versions you expect.\nPlease carefully study the documentation linked above for further help.\n\nOriginal error was: dlopen(/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/core/_multiarray_umath.cpython-310-darwin.so, 0x0002): tried: '/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/core/_multiarray_umath.cpython-310-darwin.so' (mach-o file, but is an incompatible architecture (have 'arm64', need 'x86_64'))\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/core/__init__.py:23\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 23\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m multiarray\n\u001b[1;32m     24\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/core/multiarray.py:10\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mfunctools\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m overrides\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m _multiarray_umath\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/core/overrides.py:6\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_multiarray_umath\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      7\u001b[0m     add_docstring, implement_array_function, _get_implementing_args)\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_inspect\u001b[39;00m \u001b[39mimport\u001b[39;00m getargspec\n",
      "\u001b[0;31mImportError\u001b[0m: dlopen(/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/core/_multiarray_umath.cpython-310-darwin.so, 0x0002): tried: '/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/core/_multiarray_umath.cpython-310-darwin.so' (mach-o file, but is an incompatible architecture (have 'arm64', need 'x86_64'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/Users/rohan/Documents/Research/RTGR/pfbehaviorworkflow.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/rohan/Documents/Research/RTGR/pfbehaviorworkflow.ipynb#W0sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m get_ipython()\u001b[39m.\u001b[39;49mrun_line_magic(\u001b[39m'\u001b[39;49m\u001b[39mmatplotlib\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mwidget\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rohan/Documents/Research/RTGR/pfbehaviorworkflow.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rohan/Documents/Research/RTGR/pfbehaviorworkflow.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mphotometry_preprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m \n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2294\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2292\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mlocal_ns\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2293\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2294\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2295\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/IPython/core/magics/pylab.py:99\u001b[0m, in \u001b[0;36mPylabMagics.matplotlib\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAvailable matplotlib backends: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m backends_list)\n\u001b[1;32m     98\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 99\u001b[0m     gui, backend \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshell\u001b[39m.\u001b[39;49menable_matplotlib(args\u001b[39m.\u001b[39;49mgui\u001b[39m.\u001b[39;49mlower() \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(args\u001b[39m.\u001b[39;49mgui, \u001b[39mstr\u001b[39;49m) \u001b[39melse\u001b[39;49;00m args\u001b[39m.\u001b[39;49mgui)\n\u001b[1;32m    100\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_show_matplotlib_backend(args\u001b[39m.\u001b[39mgui, backend)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3444\u001b[0m, in \u001b[0;36mInteractiveShell.enable_matplotlib\u001b[0;34m(self, gui)\u001b[0m\n\u001b[1;32m   3423\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39menable_matplotlib\u001b[39m(\u001b[39mself\u001b[39m, gui\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   3424\u001b[0m     \u001b[39m\"\"\"Enable interactive matplotlib and inline figure support.\u001b[39;00m\n\u001b[1;32m   3425\u001b[0m \n\u001b[1;32m   3426\u001b[0m \u001b[39m    This takes the following steps:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3442\u001b[0m \u001b[39m        display figures inline.\u001b[39;00m\n\u001b[1;32m   3443\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3444\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib_inline\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend_inline\u001b[39;00m \u001b[39mimport\u001b[39;00m configure_inline_support\n\u001b[1;32m   3446\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mIPython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m pylabtools \u001b[39mas\u001b[39;00m pt\n\u001b[1;32m   3447\u001b[0m     gui, backend \u001b[39m=\u001b[39m pt\u001b[39m.\u001b[39mfind_gui_and_backend(gui, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpylab_gui_select)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/matplotlib_inline/backend_inline.py:6\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m\"\"\"A matplotlib backend for publishing figures via display_data\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Copyright (c) IPython Development Team.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m# Distributed under the terms of the BSD 3-Clause License.\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackends\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend_agg\u001b[39;00m \u001b[39mimport\u001b[39;00m (  \u001b[39m# noqa\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     new_figure_manager,\n\u001b[1;32m      9\u001b[0m     FigureCanvasAgg,\n\u001b[1;32m     10\u001b[0m     new_figure_manager_given_figure,\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mimport\u001b[39;00m colors\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/matplotlib/__init__.py:104\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtempfile\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpackaging\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mversion\u001b[39;00m \u001b[39mimport\u001b[39;00m parse \u001b[39mas\u001b[39;00m parse_version\n\u001b[1;32m    107\u001b[0m \u001b[39m# cbook must import matplotlib only within function\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[39m# definitions, so it is safe to import from it here.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/__init__.py:144\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[39m# Allow distributors to run custom init code\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m _distributor_init\n\u001b[0;32m--> 144\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m core\n\u001b[1;32m    145\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m    146\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m compat\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/core/__init__.py:49\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m     27\u001b[0m \n\u001b[1;32m     28\u001b[0m \u001b[39mIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39m\"\"\"\u001b[39m \u001b[39m%\u001b[39m (sys\u001b[39m.\u001b[39mversion_info[\u001b[39m0\u001b[39m], sys\u001b[39m.\u001b[39mversion_info[\u001b[39m1\u001b[39m], sys\u001b[39m.\u001b[39mexecutable,\n\u001b[1;32m     48\u001b[0m         __version__, exc)\n\u001b[0;32m---> 49\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(msg)\n\u001b[1;32m     50\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m     \u001b[39mfor\u001b[39;00m envkey \u001b[39min\u001b[39;00m env_added:\n",
      "\u001b[0;31mImportError\u001b[0m: \n\nIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\n\nImporting the numpy C-extensions failed. This error can happen for\nmany reasons, often due to issues with your setup or how NumPy was\ninstalled.\n\nWe have compiled some common reasons and troubleshooting tips at:\n\n    https://numpy.org/devdocs/user/troubleshooting-importerror.html\n\nPlease note and check the following:\n\n  * The Python version is: Python3.10 from \"/usr/local/bin/python3\"\n  * The NumPy version is: \"1.22.0\"\n\nand make sure that they are the versions you expect.\nPlease carefully study the documentation linked above for further help.\n\nOriginal error was: dlopen(/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/core/_multiarray_umath.cpython-310-darwin.so, 0x0002): tried: '/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/core/_multiarray_umath.cpython-310-darwin.so' (mach-o file, but is an incompatible architecture (have 'arm64', need 'x86_64'))\n"
     ]
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "from photometry_preprocessing import * \n",
    "from photometry_smoothing import *\n",
    "from photometry_correcting import * \n",
    "from photometry_eventanalysis import * \n",
    "from photometry_variationanalysis import *\n",
    "from photometry_visualization import * \n",
    "from scalebars import *\n",
    "import deeplabcut_returnanalysis as dlcra \n",
    "import pandas as pd \n",
    "import warnings\n",
    "import functools\n",
    "import operator\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from matplotlib.lines import Line2D\n",
    "matplotlib.rcParams['font.size'] = 10\n",
    "plt.style.use('seaborn-deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paths to data folders \n",
    "FL = ['/scratch/rhs112/FL/RTGR-173_2022-02-23', '/scratch/rhs112/FL/RTGR-173_2022-04-17', '/scratch/rhs112/FL/RTGR-174_2022-02-24', \n",
    "    '/scratch/rhs112/FL/RTGR-174_2022-04-18', '/scratch/rhs112/FL/RTGR-176_2022-03-12', '/scratch/rhs112/FL/RTGR-176_2022-04-20', '/scratch/rhs112/FL/RTGR-121_2022-01-02']\n",
    "ECD = ['/scratch/rhs112/ECD/RTGR-104_2022-01-21', '/scratch/rhs112/ECD/RTGR-177_2022-02-28', '/scratch/rhs112/ECD/RTGR-177_2022-04-21',\n",
    "    '/scratch/rhs112/ECD/RTGR-178_2022-04-22','/scratch/rhs112/ECD/RTGR-179_2022-03-02', '/scratch/rhs112/ECD/RTGR-179_2022-04-23']\n",
    "ECDControl = ['/scratch/rhs112/ECDControl/RTGR-191_2022-03-14', '/scratch/rhs112/ECDControl/RTGR-191_2022-03-30', '/scratch/rhs112/ECDControl/RTGR-192_2022-03-15',\n",
    "            '/scratch/rhs112/ECDControl/RTGR-192_2022-03-31', '/scratch/rhs112/ECDControl/RTGR-193_2022-03-16', '/scratch/rhs112/ECDControl/RTGR-193_2022-04-01',\n",
    "            '/scratch/rhs112/ECDControl/RTGR-200_2022-06-14', '/scratch/rhs112/ECDControl/RTGR-200_2022-06-18']\n",
    "ECD13A = ['/scratch/rhs112/ECD1.3a/RTGR-108_2022-01-19', '/scratch/rhs112/ECD1.3a/RTGR-110_2022-02-02', '/scratch/rhs112/ECD1.3a/RTGR-182_2022-03-05',\n",
    "        '/scratch/rhs112/ECD1.3a/RTGR-182_2022-04-02', '/scratch/rhs112/ECD1.3a/RTGR-182_2022-04-24', '/scratch/rhs112/ECD1.3a/RTGR-182_2022-04-29',\n",
    "        '/scratch/rhs112/ECD1.3a/RTGR-184_2022-03-08', '/scratch/rhs112/ECD1.3a/RTGR-184_2022-04-04', '/scratch/rhs112/ECD1.3a/RTGR-184_2022-04-26']\n",
    "WTFL = ['/scratch/rhs112/WTFL/RTGR-208_2022-08-01', '/scratch/rhs112/WTFL/RTGR-210_2022-08-03', \n",
    "        '/scratch/rhs112/WTFL/RTGR-208_2022-09-06', '/scratch/rhs112/WTFL/RTGR-209_2022-09-07',\n",
    "       '/scratch/rhs112/WTFL/RTGR-210_2022-09-08']\n",
    "WTFL_unfasted = ['/scratch/rhs112/WTFL/RTGR-208_2022-09-12', '/scratch/rhs112/WTFL/RTGR-209_2022-09-13',\n",
    "                '/scratch/rhs112/WTFL/RTGR-210_2022-09-14']\n",
    "WTECD = ['/scratch/rhs112/WTECD/RTGR-211_2022-08-04', '/scratch/rhs112/WTECD/RTGR-212_2022-08-05',\n",
    "        '/scratch/rhs112/WTECD/RTGR-211_2022-09-09', '/scratch/rhs112/WTECD/RTGR-212_2022-09-10']\n",
    "WTECD_unfasted = ['/scratch/rhs112/RTGR-211_2022-09-15']\n",
    "ECD14A = ['/scratch/rhs112/ECD1.4a/RTGR-213_2022-08-08']\n",
    "ECD14B = ['/scratch/rhs112/ECD1.4b/RTGR-215_2022-08-10', '/scratch/rhs112/ECD1.4b/RTGR-216_2022-08-11']\n",
    "ECD14C = ['/scratch/rhs112/ECD1.4c/RTGR-217_2022-08-12']\n",
    "ECD13A_anesthesia = ['/scratch/rhs112/anesthesia/RTGR-110_2021-12-30-4h-ane']\n",
    "FL_anesthesia = ['/scratch/rhs112/anesthesia/RTGR-130-A-4h-20220608', '/scratch/rhs112/anesthesia/RTGR-161-A-4h-20220608'] \n",
    "ECD_anesthesia = ['/scratch/rhs112/anesthesia/RTGR-162-A-4h-20220606', '/scratch/rhs112/anesthesia/RTGR-163-A-4h-20220607', '/scratch/rhs112/anesthesia/RTGR-164-A-4h-20220607']\n",
    "anesthesia = ECD_anesthesia + FL_anesthesia + ECD13A_anesthesia\n",
    "\n",
    "pixel_per_mms = {\n",
    "    '/scratch/rhs112/FL/RTGR-173_2022-02-23': 0.670588,\n",
    "    '/scratch/rhs112/FL/RTGR-173_2022-04-17': 0.670646,\n",
    "    '/scratch/rhs112/FL/RTGR-174_2022-02-24': 0.671368,\n",
    "    '/scratch/rhs112/FL/RTGR-174_2022-04-18': 0.682581,\n",
    "    '/scratch/rhs112/FL/RTGR-176_2022-03-12': 0.647299,\n",
    "    '/scratch/rhs112/FL/RTGR-176_2022-04-20': 0.670749,\n",
    "    '/scratch/rhs112/FL/RTGR-121_2022-01-02': 0.538308,\n",
    "    '/scratch/rhs112/ECD/RTGR-104_2022-01-21': 0.670614,\n",
    "    '/scratch/rhs112/ECD/RTGR-177_2022-02-28': 0.656047,\n",
    "    '/scratch/rhs112/ECD/RTGR-177_2022-04-21': 0.676701,\n",
    "    '/scratch/rhs112/ECD/RTGR-178_2022-04-22': 0.676477,\n",
    "    '/scratch/rhs112/ECD/RTGR-179_2022-03-02': 0.644286,\n",
    "    '/scratch/rhs112/ECD/RTGR-179_2022-04-23': 0.659145,\n",
    "    '/scratch/rhs112/ECDControl/RTGR-191_2022-03-14': 0.653266,\n",
    "    '/scratch/rhs112/ECDControl/RTGR-191_2022-03-30': 0.668295,\n",
    "    '/scratch/rhs112/ECDControl/RTGR-192_2022-03-15': 0.670904,\n",
    "    '/scratch/rhs112/ECDControl/RTGR-192_2022-03-31': 0.679412,\n",
    "    '/scratch/rhs112/ECDControl/RTGR-193_2022-03-16': 0.670691,\n",
    "    '/scratch/rhs112/ECDControl/RTGR-193_2022-04-01': 0.676572,\n",
    "    '/scratch/rhs112/ECDControl/RTGR-200_2022-06-14': 0.653107,\n",
    "    '/scratch/rhs112/ECDControl/RTGR-200_2022-06-18': 0.685698,\n",
    "    '/scratch/rhs112/ECD1.3a/RTGR-108_2022-01-19': 0.673632,\n",
    "    '/scratch/rhs112/ECD1.3a/RTGR-110_2022-02-02': 0.673555,\n",
    "    '/scratch/rhs112/ECD1.3a/RTGR-182_2022-03-05': 0.670691,\n",
    "    '/scratch/rhs112/ECD1.3a/RTGR-182_2022-04-02': 0.673587,\n",
    "    '/scratch/rhs112/ECD1.3a/RTGR-182_2022-04-24': 0.678698,\n",
    "    '/scratch/rhs112/ECD1.3a/RTGR-182_2022-04-29': 0.664732,\n",
    "    '/scratch/rhs112/ECD1.3a/RTGR-184_2022-03-08': 0.662239,\n",
    "    '/scratch/rhs112/ECD1.3a/RTGR-184_2022-04-04': 0.676477,\n",
    "    '/scratch/rhs112/ECD1.3a/RTGR-184_2022-04-26': 0.661765,\n",
    "    '/scratch/rhs112/WTFL/RTGR-208_2022-08-01': 0.67942,\n",
    "    '/scratch/rhs112/WTFL/RTGR-210_2022-08-03': 0.68266,\n",
    "    '/scratch/rhs112/WTFL/RTGR-208_2022-09-06': 0.67711,\n",
    "    '/scratch/rhs112/WTFL/RTGR-209_2022-09-07': 0.68834, \n",
    "    '/scratch/rhs112/WTFL/RTGR-210_2022-09-08': 0.67957,\n",
    "    '/scratch/rhs112/WTFL/RTGR-208_2022-09-12': 0.68529, \n",
    "    '/scratch/rhs112/WTFL/RTGR-209_2022-09-13': 0.68636,\n",
    "    '/scratch/rhs112/WTFL/RTGR-210_2022-09-14': 0.67943,\n",
    "    '/scratch/rhs112/WTECD/RTGR-211_2022-08-04': 0.68266,\n",
    "    '/scratch/rhs112/WTECD/RTGR-212_2022-08-05': 0.67772,\n",
    "    '/scratch/rhs112/WTECD/RTGR-211_2022-09-09': 0.68440, \n",
    "    '/scratch/rhs112/WTECD/RTGR-212_2022-09-10': 0.67699,\n",
    "    '/scratch/rhs112/ECD1.4a/RTGR-213_2022-08-08': 0.67724,\n",
    "    '/scratch/rhs112/ECD1.4b/RTGR-215_2022-08-10': 0.67405,\n",
    "    '/scratch/rhs112/ECD1.4b/RTGR-216_2022-08-11': 0.65300,\n",
    "    '/scratch/rhs112/ECD1.4c/RTGR-217_2022-08-12': 0.65888}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training results for DeepLabCut model are recorded here (for plotting later). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training was stopped at 430,000 iterations and resumed until 825,000 iterations \n",
    "'''Results for 550000  training iterations: 95 1 train error: 1.57 pixels. Test error: 2.74  pixels.\n",
    "With pcutoff of 0.9  train error: 1.57 pixels. Test error: 2.74 pixels\n",
    "Thereby, the errors are given by the average distances between the labels by DLC and the scorer.''' \n",
    "iterations = [5000, 10000, 15000, 20000, 25000, 30000, 35000, 40000, 45000, 50000, 55000, 60000, 65000, 70000, 75000, 80000, 85000, 90000, 95000, 100000, 105000, 110000, 115000, 120000, 125000, 130000, 135000, 140000, 145000, 150000, 155000, 160000, 165000, 170000, 175000, 180000, 185000, 190000, 195000, 200000, 205000, 210000, 215000, 220000, 225000, 230000, 235000, 240000, 245000, 250000, 255000, 260000, 265000, 270000, 275000, 280000, 285000, 290000, 295000, 300000, 305000, 310000, 315000, 320000, 325000, 330000, 335000, 340000, 345000, 350000, 355000, 360000, 365000, 370000, 375000, 380000, 385000, 390000, 395000, 400000, 405000, 410000, 415000, 420000, 425000, 430000, 430000, 435000, 440000, 445000, 450000, 455000, 460000, 465000, 470000, 475000, 480000, 485000, 490000, 495000, 500000, 505000, 510000, 515000, 520000, 525000, 530000, 535000, 540000, 545000, 550000, 555000, 560000, 565000, 570000, 575000, 580000, 585000, 590000, 595000, 600000, 605000, 610000, 615000, 620000, 625000, 630000, 635000, 640000, 645000, 650000, 665000, 670000, 675000, 680000, 685000, 690000, 695000, 700000, 705000, 710000, 715000, 720000, 725000, 730000, 735000, 740000, 745000, 750000, 755000, 760000, 765000, 770000, 775000, 780000, 785000, 790000, 795000, 800000, 805000, 810000, 815000, 820000, 825000]\n",
    "\n",
    "losses = [0.0300, 0.0213, 0.0192, 0.0139, 0.0124, 0.0113, 0.0108, 0.0101, 0.0100, 0.0095, 0.0092, 0.0090, 0.0086, 0.0084, 0.0083, 0.0081, 0.0079, 0.0082, 0.0078, 0.0075, 0.0075, 0.0074, 0.0070, 0.0069, 0.0070, 0.0068, 0.0070, 0.0068, 0.0066, 0.0065, 0.0065, 0.0064, 0.0064, 0.0061, 0.0062, 0.0060, 0.0061, 0.0059, 0.0058, 0.0057, 0.0055, 0.0055, 0.0057, 0.0055, 0.0055, 0.0055, 0.0055, 0.0053, 0.0053, 0.0054, 0.0051, 0.0051, 0.0052, 0.0053, 0.0051, 0.0052, 0.0051, 0.0049, 0.0050, 0.0051, 0.0047, 0.0048, 0.0048, 0.0048, 0.0047, 0.0049, 0.0048, 0.0047, 0.0046, 0.0045, 0.0046, 0.0046, 0.0046, 0.0047, 0.0046, 0.0045, 0.0044, 0.0044, 0.0044, 0.0043, 0.0044, 0.0044, 0.0044, 0.0043, 0.0042, 0.0042, 0.0038, 0.0037, 0.0037, 0.0036, 0.0036, 0.0036, 0.0035, 0.0035, 0.0035, 0.0035, 0.0034, 0.0035, 0.0034, 0.0034, 0.0034, 0.0034, 0.0034, 0.0034, 0.0035, 0.0034, 0.0034, 0.0034, 0.0033, 0.0034, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0034, 0.0033, 0.0033, 0.0032, 0.0032, 0.0033, 0.0033, 0.0032, 0.0033, 0.0032, 0.0033, 0.0032, 0.0032, 0.0032, 0.0032, 0.0032, 0.0032, 0.0033, 0.0032, 0.0032, 0.0032, 0.0032, 0.0033, 0.0031, 0.0031, 0.0031, 0.0032, 0.0032, 0.0032, 0.0031, 0.0032, 0.0031, 0.0031, 0.0031, 0.0030, 0.0031, 0.0031, 0.0031, 0.0030, 0.0031, 0.0031, 0.0030, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0030]\n",
    "\n",
    "pixel_error_iterations = [25000, 50000,75000,100000,125000,150000,175000,200000,225000,250000, 275000,300000, 325000, 350000, 375000, 400000, 425000, 450000, 475000, 500000, 525000, 550000, 575000, 600000, 625000, 650000, 675000, 700000, 725000, 750000, 775000, 800000, 825000]\n",
    "training_error = [5.03, 4.2, 3.57, 2.99, 3.26, 3.04, 2.95, 2.72, 2.7, 2.46, 2.43, 2.21, 3.05, 2.38, 2.15, 2.22, 2.28, 1.77, 1.63, 1.65, 1.78, 1.57, 1.75, 1.73, 1.65, 1.53, 1.55, 1.72, 1.55, 1.54, 1.71, 1.67, 1.68]\n",
    "test_error = [5.11, 4.73, 3.75, 3.46, 3.79, 3.56, 3.53, 3.23, 3.43, 3.2, 3.04, 2.88, 4.31, 3.31, 3.2, 3.07, 3.12, 2.85, 2.79, 2.73, 2.84, 2.74, 2.72, 2.78, 2.79, 2.79, 2.82, 2.87, 2.82, 2.81, 2.8, 2.9, 2.9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepLabCut Data Processing\n",
    "Once pose estimation data has been returned by DeepLabCut, it must be translated into behavior onsets/offsets, e.g. immobility, micromovements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Repeat the below for each set of recordings to analyze.\n",
    "Requires a path to the output .h5 DeepLabCut file, ROI .csv file, and pixel_per_mm for each recording \n",
    "Calculates \"behaviors\" based on speed of animal (criteria mentioned in script), saves results in format specified in helper script\n",
    "\"\"\"\n",
    "\n",
    "for path in [WTFL_unfasted[-1]]:\n",
    "    print(path)\n",
    "    foldername = path.rsplit('/', 2)[-1] #splits folder name from path\n",
    "    dlcfile = f'{path}/{foldername}_croppedDLC_resnet50_FullModelApr12shuffle1_550000.h5'\n",
    "    roi_output = f'{path}/ROIs.csv'\n",
    "    pixel_per_mm = pixel_per_mms[path]\n",
    "    dlcra.dlcanalysis(f'{path}/', dlcfile, roi_output, pixel_per_mm=pixel_per_mm, compare_manualannotations=False, threshold_speed=0.75, immobilitytime=120, wiggletime=10)\n",
    "print('WTFL')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check confidence of DLC output by plotting % frames with confidence < 0.99 \n",
    "ECD_errors = {'tip_of_head': [], 'lefthip': [], 'righthip': [], 'tail_base': []}\n",
    "FL_errors = {'tip_of_head': [], 'lefthip': [], 'righthip': [], 'tail_base': []}\n",
    "ECDControl_errors = {'tip_of_head': [], 'lefthip': [], 'righthip': [], 'tail_base': []}\n",
    "ECD13A_errors = {'tip_of_head': [], 'lefthip': [], 'righthip': [], 'tail_base': []}\n",
    "\n",
    "for path in ECD:\n",
    "    with open(path + '/DLCbehaviors.yml', 'r') as file:\n",
    "        DLCbehaviors=yaml.load(file, Loader=yaml.Loader)\n",
    "    ECD_errors['tip_of_head'] += [DLCbehaviors['tip_of_head percent error']]\n",
    "    ECD_errors['lefthip'] += [DLCbehaviors['lefthip percent error']]\n",
    "    ECD_errors['righthip'] += [DLCbehaviors['righthip percent error']]\n",
    "    ECD_errors['tail_base'] += [DLCbehaviors['tail_base percent error']]\n",
    "dfECD = pd.DataFrame({k:pd.Series(v) for k,v in ECD_errors.items()})\n",
    "\n",
    "for path in FL:\n",
    "    with open(path + '/DLCbehaviors.yml', 'r') as file:\n",
    "        DLCbehaviors=yaml.load(file, Loader=yaml.Loader)\n",
    "    FL_errors['tip_of_head'] += [DLCbehaviors['tip_of_head percent error']]\n",
    "    FL_errors['lefthip'] += [DLCbehaviors['lefthip percent error']]\n",
    "    FL_errors['righthip'] += [DLCbehaviors['righthip percent error']]\n",
    "    FL_errors['tail_base'] += [DLCbehaviors['tail_base percent error']]\n",
    "dfFL = pd.DataFrame({k:pd.Series(v) for k,v in FL_errors.items()})\n",
    "\n",
    "for path in ECDControl: \n",
    "    with open(path + '/DLCbehaviors.yml', 'r') as file:\n",
    "        DLCbehaviors=yaml.load(file, Loader=yaml.Loader)\n",
    "    ECDControl_errors['tip_of_head'] += [DLCbehaviors['tip_of_head percent error']]\n",
    "    ECDControl_errors['lefthip'] += [DLCbehaviors['lefthip percent error']]\n",
    "    ECDControl_errors['righthip'] += [DLCbehaviors['righthip percent error']]\n",
    "    ECDControl_errors['tail_base'] += [DLCbehaviors['tail_base percent error']]\n",
    "dfECDControl = pd.DataFrame({k:pd.Series(v) for k,v in ECDControl_errors.items()})\n",
    "\n",
    "for path in ECD13A:\n",
    "    with open(path + '/DLCbehaviors.yml', 'r') as file:\n",
    "        DLCbehaviors=yaml.load(file, Loader=yaml.Loader)\n",
    "    ECD13A_errors['tip_of_head'] += [DLCbehaviors['tip_of_head percent error']]\n",
    "    ECD13A_errors['lefthip'] += [DLCbehaviors['lefthip percent error']]\n",
    "    ECD13A_errors['righthip'] += [DLCbehaviors['righthip percent error']]\n",
    "    ECD13A_errors['tail_base'] += [DLCbehaviors['tail_base percent error']]\n",
    "dfECD13A = pd.DataFrame({k:pd.Series(v) for k,v in ECD13A_errors.items()})\n",
    "\n",
    "df = pd.concat([dfFL, dfECD, dfECDControl, dfECD13A], axis=1, keys = ['FL', 'ECD', 'ECDControl', 'ECD1.3A'])\n",
    "df.columns = df.columns.rename(['sensor', 'bodypart'])\n",
    "df = df.unstack().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1, figsize=(8,5)) \n",
    "g1 = sns.barplot(x='bodypart', y=0, hue='sensor', data=df, ci=95, palette='magma', errwidth=0.75, capsize=0.05, ax=ax1)\n",
    "ax1.set_xlabel('Labeled Bodypart')\n",
    "ax1.set_ylabel('% Frames Labeled < 99% Likely', fontsize=12)\n",
    "fig.suptitle('Bodypart Estimation Likelihoods For Each Sensor')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning curve of DeepLabCut network. \n",
    "fig, ax1 = plt.subplots()\n",
    "ax2 = ax1.twinx()\n",
    "ax1.plot(iterations, losses, color='black', label='Loss')\n",
    "ax2.plot(pixel_error_iterations, training_error, color='orangered', label='Training Error')\n",
    "ax2.plot(pixel_error_iterations, test_error, color='darkviolet', label='Test Error')\n",
    "ax1.vlines(550000, ymin=0,ymax=0.033, linestyles='dashed', lw=0.75, colors='black' )\n",
    "ax1.set_xlabel('Iterations')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax2.set_ylabel('Error (pixels)')\n",
    "ax1.legend(loc='lower left')\n",
    "ax2.legend()\n",
    "fig.suptitle('Learning Curve of DeepLabCut Network')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also important to check the duration of various events, like meals and immobility. Will help in figuring out the right way to visualize data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check distribution of behavior durations (helps figure out right view window to set later on)\n",
    "#Sleep \n",
    "all_paths = [path for sensor in [FL, ECD, ECD13A, ECDControl, WTFL, WTECD, ECD14A, ECD14B, ECD14C] for path in sensor]\n",
    "paths = [f'{tdt_path}/ProcessedDLCBehaviors.yml' for tdt_path in all_paths]\n",
    "\n",
    "paths2 = [[f'{tdt_path}/ProcessedManualBehaviors.yml' for tdt_path in ECD], [f'{tdt_path}/ProcessedManualBehaviors.yml' for tdt_path in FL]]\n",
    "paths2 = functools.reduce(operator.iconcat, paths2, [])\n",
    "\n",
    "\n",
    "\n",
    "fig, ax1 = plt.subplots(1, figsize=(8,5))\n",
    "ax1 = visualize_behaviordistribution(\n",
    "            ax1,\n",
    "            behavior_name = 'All Immobility Events',\n",
    "            label1 = 'DLC', \n",
    "            both = True,\n",
    "            label2 = 'Manual',\n",
    "            loadbehaviors= True,\n",
    "            paths = paths,\n",
    "            paths2 = paths2,\n",
    "            behavior_dictname= 'immobility',\n",
    "            behavior_dictname2= 'immobility')\n",
    "#plt.savefig('/scratch/rhs112/Sleep_Distribution.png')\n",
    "fig.tight_layout()\n",
    "#Meals \n",
    "fig, ax2 = plt.subplots(1, figsize=(8,5))\n",
    "ax2 = visualize_behaviordistribution(\n",
    "            ax2,\n",
    "            behavior_name = 'All Meal Events',\n",
    "            label1 = 'Manual',\n",
    "            binsize=200,\n",
    "            both = False,\n",
    "            loadbehaviors= True,\n",
    "            paths = paths2,\n",
    "            behavior_dictname= 'meal')\n",
    "#plt.savefig('/scratch/rhs112/Meal_Distribution.png')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize behavior distributions separately for each sensor type \n",
    "\n",
    "fig, ax1 = plt.subplots(1, figsize=(8,5))\n",
    "ax1 = visualize_behaviordistribution(\n",
    "        ax1,\n",
    "        behavior_name = 'FL Sleep Events',\n",
    "        label1 = 'DLC',\n",
    "        both = True,\n",
    "        label2 = 'Manual',\n",
    "        loadbehaviors=True,\n",
    "        paths = [f'{tdt_path}/ProcessedDLCBehaviors.yml' for tdt_path in FL],\n",
    "        paths2 = [f'{tdt_path}/ProcessedManualBehaviors.yml' for tdt_path in FL],\n",
    "        behavior_dictname= 'sleep',\n",
    "        behavior_dictname2= 'sleep')\n",
    "fig, ax2 = plt.subplots(1, figsize=(8,5))\n",
    "ax2 = visualize_behaviordistribution(\n",
    "        ax2,\n",
    "        behavior_name = 'ECD Sleep Events',\n",
    "        label1 = 'DLC',\n",
    "        both = True,\n",
    "        label2 = 'Manual',\n",
    "        loadbehaviors=True,\n",
    "        paths = [f'{tdt_path}/ProcessedDLCBehaviors.yml' for tdt_path in ECD],\n",
    "        paths2 = [f'{tdt_path}/ProcessedManualBehaviors.yml' for tdt_path in ECD],\n",
    "        behavior_dictname= 'sleep',\n",
    "        behavior_dictname2= 'sleep')\n",
    "fig, ax3 = plt.subplots(1, figsize=(8,5))\n",
    "ax3 = visualize_behaviordistribution(\n",
    "        ax3,\n",
    "        behavior_name = 'ECD Control Sleep Events',\n",
    "        label1 = 'DLC',\n",
    "        loadbehaviors=True,\n",
    "        paths = [f'{tdt_path}/ProcessedDLCBehaviors.yml' for tdt_path in ECDControl],\n",
    "        behavior_dictname= 'sleep')\n",
    "fig, ax4 = plt.subplots(1, figsize=(8,5))\n",
    "ax4 = visualize_behaviordistribution(\n",
    "        ax4,\n",
    "        behavior_name = 'ECD 1.3a Sleep Events',\n",
    "        label1 = 'DLC',\n",
    "        loadbehaviors=True,\n",
    "        paths = [f'{tdt_path}/ProcessedDLCBehaviors.yml' for tdt_path in ECD13A],\n",
    "        behavior_dictname= 'sleep')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1, figsize=(8,5))\n",
    "ax1 = visualize_behaviordistribution(\n",
    "        ax1,\n",
    "        behavior_name = 'FL Meal Events',\n",
    "        label1 = 'Manual',\n",
    "        binsize=200,\n",
    "        loadbehaviors=True,\n",
    "        paths = [f'{tdt_path}/ProcessedManualBehaviors.yml' for tdt_path in FL],\n",
    "        behavior_dictname= 'meal')\n",
    "fig, ax2 = plt.subplots(1, figsize=(8,5))\n",
    "ax2 = visualize_behaviordistribution(\n",
    "        ax2,\n",
    "        behavior_name = 'ECD Meal Events',\n",
    "        label1 = 'Manual',\n",
    "        binsize=200,\n",
    "        loadbehaviors=True,\n",
    "        paths = [f'{tdt_path}/ProcessedManualBehaviors.yml' for tdt_path in ECD],\n",
    "        behavior_dictname= 'meal')\n",
    "fig, ax3 = plt.subplots(1, figsize=(8,5))\n",
    "ax3 = visualize_behaviordistribution(\n",
    "        ax3,\n",
    "        behavior_name = 'ECD Control Meal Events',\n",
    "        label1 = 'Manual',\n",
    "        binsize=200,\n",
    "        loadbehaviors=True,\n",
    "        paths = [f'{tdt_path}/ProcessedDLCBehaviors.yml' for tdt_path in ECDControl],\n",
    "        behavior_dictname= 'meal')\n",
    "fig, ax4 = plt.subplots(1, figsize=(8,5))\n",
    "ax4 = visualize_behaviordistribution(\n",
    "        ax4,\n",
    "        behavior_name = 'ECD 1.3a Meal Events',\n",
    "        label1 = 'Manual',\n",
    "        binsize=200,\n",
    "        loadbehaviors=True,\n",
    "        paths = [f'{tdt_path}/ProcessedDLCBehaviors.yml' for tdt_path in ECD13A],\n",
    "        behavior_dictname= 'meal')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also validate that animal behaviors do not significantly vary between conditions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check distribution of behaviors/hr of recording between sensor types, as well as mean velocity/recording \n",
    "FL_behaviors = {'manualwiggles': [], 'DLCwiggles': [], 'manualsleep': [], 'DLCsleep': [], 'meal': [], 'speed': []}\n",
    "ECD_behaviors = {'manualwiggles': [], 'DLCwiggles': [], 'manualsleep': [], 'DLCsleep': [], 'meal': [], 'speed': []}\n",
    "ECDControl_behaviors = {'DLCwiggles': [], 'DLCsleep': [], 'meal': [], 'speed': []}\n",
    "ECD13A_behaviors = {'DLCwiggles': [], 'DLCsleep': [], 'meal': [], 'speed': []}\n",
    "\n",
    "for path in FL:\n",
    "    manualbehaviors, DLCbehaviors = load_processed_behaviors(path + '/')\n",
    "    time = load_data(f'{path}/time.npy')\n",
    "    time = time[-1] / 3600\n",
    "    FL_behaviors['manualwiggles'] += [len(manualbehaviors['wiggles']) / time]\n",
    "    FL_behaviors['DLCwiggles'] += [len(DLCbehaviors['wiggle_onsets']) / time]\n",
    "    FL_behaviors['manualsleep'] += [len(manualbehaviors['sleep_onsets']) / time]\n",
    "    FL_behaviors['DLCsleep'] += [len(DLCbehaviors['sleep_onsets']) / time]\n",
    "    try:\n",
    "        FL_behaviors['meal'] += [len(manualbehaviors['meal_onsets']) / time]\n",
    "    except:\n",
    "        FL_behaviors['meal'] += [len(DLCbehaviors['meal_onsets']) / time]\n",
    "    temp = pd.read_hdf(f'{path}/dlcanalysis.h5')\n",
    "    temp = temp['tip_of_head', 'avg'][::10]\n",
    "    FL_behaviors['speed'] += [temp.mean()]\n",
    "    \n",
    "dfFL = pd.DataFrame({k:pd.Series(v) for k,v in FL_behaviors.items()})\n",
    "\n",
    "for path in ECD:\n",
    "    manualbehaviors, DLCbehaviors = load_processed_behaviors(path + '/')\n",
    "    time = load_data(f'{path}/time.npy')\n",
    "    time = time[-1] / 3600\n",
    "    ECD_behaviors['manualwiggles'] += [len(manualbehaviors['wiggles']) / time]\n",
    "    ECD_behaviors['DLCwiggles'] += [len(DLCbehaviors['wiggle_onsets']) / time]\n",
    "    ECD_behaviors['manualsleep'] += [len(manualbehaviors['sleep_onsets']) / time]\n",
    "    ECD_behaviors['DLCsleep'] += [len(DLCbehaviors['sleep_onsets']) / time]\n",
    "    try:\n",
    "        ECD_behaviors['meal'] += [len(manualbehaviors['meal_onsets']) / time]\n",
    "    except:\n",
    "        ECD_behaviors['meal'] += [len(DLCbehaviors['meal_onsets']) / time]\n",
    "    temp = pd.read_hdf(f'{path}/dlcanalysis.h5')\n",
    "    temp = temp['tip_of_head', 'avg'][::10]\n",
    "    ECD_behaviors['speed'] += [temp.mean()]\n",
    "dfECD = pd.DataFrame({k:pd.Series(v) for k,v in ECD_behaviors.items()})\n",
    "\n",
    "for path in ECDControl:\n",
    "    time = load_data(f'{path}/time.npy')\n",
    "    time = time[-1] / 3600\n",
    "    _, DLCbehaviors = load_processed_behaviors(path + '/', manual=False)\n",
    "    ECDControl_behaviors['DLCwiggles'] += [len(DLCbehaviors['wiggle_onsets']) / time]\n",
    "    ECDControl_behaviors['DLCsleep'] += [len(DLCbehaviors['sleep_onsets']) / time]\n",
    "    ECDControl_behaviors['meal'] += [len(DLCbehaviors['meal_onsets']) / time]\n",
    "    temp = pd.read_hdf(f'{path}/dlcanalysis.h5')\n",
    "    temp = temp['tip_of_head', 'avg'][::10]\n",
    "    ECDControl_behaviors['speed'] += [temp.mean()]\n",
    "dfECDControl = pd.DataFrame({k:pd.Series(v) for k,v in ECDControl_behaviors.items()})\n",
    "\n",
    "for path in ECD13A:\n",
    "    time = load_data(f'{path}/time.npy')\n",
    "    time = time[-1] / 3600\n",
    "    _, DLCbehaviors = load_processed_behaviors(path + '/', manual=False)\n",
    "    ECD13A_behaviors['DLCwiggles'] += [len(DLCbehaviors['wiggle_onsets']) / time]\n",
    "    ECD13A_behaviors['DLCsleep'] += [len(DLCbehaviors['sleep_onsets']) / time]\n",
    "    ECD13A_behaviors['meal'] += [len(DLCbehaviors['meal_onsets']) / time]\n",
    "    temp = pd.read_hdf(f'{path}/dlcanalysis.h5')\n",
    "    temp = temp['tip_of_head', 'avg'][::10]\n",
    "    ECD13A_behaviors['speed'] += [temp.mean()]\n",
    "dfECD13A = pd.DataFrame({k:pd.Series(v) for k,v in ECD13A_behaviors.items()})\n",
    "\n",
    "df = pd.concat([dfFL, dfECD, dfECDControl, dfECD13A], axis=1, keys = ['FL', 'ECD', 'ECDControl', 'ECD13A'])\n",
    "df.columns = df.columns.rename(['sensor', 'behavior'])\n",
    "df = df.unstack().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1, figsize=(8,5))\n",
    "g1 = sns.barplot(x='sensor', y=0, data=df.loc[df['behavior'] == 'manualwiggles'], ci=95, errwidth=0.75, capsize=0.05, palette='magma', ax = ax1)\n",
    "ax1.set_title('Amount of Manual Wiggles Per Hour of Recording ')\n",
    "ax1.set_ylabel('Event Count Per Hour')\n",
    "fig, ax2 = plt.subplots(1, figsize=(8,5))\n",
    "g2 = sns.barplot(x='sensor', y=0, data=df.loc[df['behavior'] == 'DLCwiggles'], ci=95, errwidth=0.75, capsize=0.05, palette='magma', ax = ax2)\n",
    "ax2.set_title('Amount of DLC Wiggles Per Hour of Recording ')\n",
    "ax2.set_ylabel('Event Count Per Hour')\n",
    "fig, ax3 = plt.subplots(1, figsize=(8,5))\n",
    "g3 = sns.barplot(x='sensor', y=0, data=df.loc[df['behavior'] == 'manualsleep'], ci=95, errwidth=0.75, capsize=0.05, palette='magma', ax = ax3)\n",
    "ax3.set_title('Amount of Manual Immobility Events Per Hour of Recording ')\n",
    "ax3.set_ylabel('Event Count Per Hour')\n",
    "fig, ax4 = plt.subplots(1, figsize=(8,5))\n",
    "g4 = sns.barplot(x='sensor', y=0, data=df.loc[df['behavior'] == 'DLCsleep'], ci=95, errwidth=0.75, capsize=0.05, palette='magma', ax = ax4)\n",
    "ax4.set_title('Amount of DLC Immobility Events Per Hour of Recording ')\n",
    "ax4.set_ylabel('Event Count Per Hour')\n",
    "fig, ax5 = plt.subplots(1, figsize=(8,5))\n",
    "g5 = sns.barplot(x='sensor', y=0, data=df.loc[df['behavior'] == 'meal'], ci=95, errwidth=0.75, capsize=0.05, palette='magma', ax = ax5)\n",
    "ax5.set_title('Amount of Meal Events Per Hour of Recording ')\n",
    "ax5.set_ylabel('Event Count Per Hour')\n",
    "fig, ax6 = plt.subplots(1, figsize=(8,5))\n",
    "g6 = sns.barplot(x='sensor', y=0, data=df.loc[df['behavior'] == 'speed'], ci=95, errwidth=0.75, capsize=0.05, palette='magma', ax = ax6)\n",
    "ax6.set_title('Mean Speed Of Each Recording ')\n",
    "ax6.set_ylabel('Speed')\n",
    "fig, ax7 = plt.subplots(1, figsize=(8,5))\n",
    "g6 = sns.boxplot(x='sensor', y=0, data=df.loc[df['behavior'] == 'speed'], width=0.75, palette='magma', ax = ax7)\n",
    "ax7.set_title('Distribution of Mean Speed Of Each Recording ')\n",
    "ax7.set_ylabel('Speed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check distribution of behavior durations across each type of sensor \n",
    "FL_behaviors = {'DLCwiggles': [], 'manualsleep': [], 'DLCsleep': [], 'meal': []}\n",
    "ECD_behaviors = {'DLCwiggles': [], 'manualsleep': [], 'DLCsleep': [], 'meal': []}\n",
    "ECDControl_behaviors = {'DLCwiggles': [], 'DLCsleep': [], 'meal': []}\n",
    "ECD13A_behaviors = {'DLCwiggles': [], 'DLCsleep': [], 'meal': []}\n",
    "\n",
    "for path in FL:\n",
    "    manualbehaviors, DLCbehaviors = load_processed_behaviors(f'{path}/')\n",
    "    FL_behaviors['DLCwiggles'] += list(np.asarray(DLCbehaviors['wiggle_offsets']) - np.asarray(DLCbehaviors['wiggle_onsets']))\n",
    "    FL_behaviors['manualsleep'] += list(np.asarray(manualbehaviors['sleep_offsets']) - np.asarray(manualbehaviors['sleep_onsets']))\n",
    "    FL_behaviors['DLCsleep'] += list(np.asarray(DLCbehaviors['sleep_offsets']) - np.asarray(DLCbehaviors['sleep_onsets']))\n",
    "    try:\n",
    "        FL_behaviors['meal'] += list(np.asarray(manualbehaviors['meal_offsets']) - np.asarray(manualbehaviors['meal_onsets']))\n",
    "    except:\n",
    "        FL_behaviors['meal'] += list(np.asarray(DLCbehaviors['meal_offsets']) - np.asarray(DLCbehaviors['meal_onsets']))\n",
    "dfFL = pd.DataFrame({k:pd.Series(v) for k,v in FL_behaviors.items()})\n",
    "\n",
    "for path in ECD:\n",
    "    manualbehaviors, DLCbehaviors = load_processed_behaviors(f'{path}/')\n",
    "    ECD_behaviors['DLCwiggles'] += list(np.asarray(DLCbehaviors['wiggle_offsets']) - np.asarray(DLCbehaviors['wiggle_onsets']))\n",
    "    ECD_behaviors['manualsleep'] += list(np.asarray(manualbehaviors['sleep_offsets']) - np.asarray(manualbehaviors['sleep_onsets']))\n",
    "    ECD_behaviors['DLCsleep'] += list(np.asarray(DLCbehaviors['sleep_offsets']) - np.asarray(DLCbehaviors['sleep_onsets']))\n",
    "    try:\n",
    "        ECD_behaviors['meal'] += list(np.asarray(manualbehaviors['meal_offsets']) - np.asarray(manualbehaviors['meal_onsets']))\n",
    "    except:\n",
    "        ECD_behaviors['meal'] += list(np.asarray(DLCbehaviors['meal_offsets']) - np.asarray(DLCbehaviors['meal_onsets']))\n",
    "dfECD = pd.DataFrame({k:pd.Series(v) for k,v in ECD_behaviors.items()})\n",
    "\n",
    "for path in ECDControl:\n",
    "    _, DLCbehaviors = load_processed_behaviors(f'{path}/', manual=False)\n",
    "    ECDControl_behaviors['DLCwiggles'] += list(np.asarray(DLCbehaviors['wiggle_offsets']) - np.asarray(DLCbehaviors['wiggle_onsets']))\n",
    "    ECDControl_behaviors['DLCsleep'] += list(np.asarray(DLCbehaviors['sleep_offsets']) - np.asarray(DLCbehaviors['sleep_onsets']))\n",
    "    ECDControl_behaviors['meal'] += list(np.asarray(DLCbehaviors['meal_offsets']) - np.asarray(DLCbehaviors['meal_onsets']))\n",
    "dfECDControl = pd.DataFrame({k:pd.Series(v) for k,v in ECDControl_behaviors.items()})\n",
    "\n",
    "for path in ECD13A:\n",
    "    _, DLCbehaviors = load_processed_behaviors(f'{path}/', manual=False)\n",
    "    ECD13A_behaviors['DLCwiggles'] += list(np.asarray(DLCbehaviors['wiggle_offsets']) - np.asarray(DLCbehaviors['wiggle_onsets']))\n",
    "    ECD13A_behaviors['DLCsleep'] += list(np.asarray(DLCbehaviors['sleep_offsets']) - np.asarray(DLCbehaviors['sleep_onsets']))\n",
    "    ECD13A_behaviors['meal'] += list(np.asarray(DLCbehaviors['meal_offsets']) - np.asarray(DLCbehaviors['meal_onsets']))\n",
    "dfECD13A = pd.DataFrame({k:pd.Series(v) for k,v in ECD13A_behaviors.items()})\n",
    "\n",
    "df = pd.concat([dfFL, dfECD, dfECDControl, dfECD13A], axis=1, keys = ['FL', 'ECD', 'ECDControl', 'ECD13A'])\n",
    "df.columns = df.columns.rename(['sensor', 'behavior'])\n",
    "df = df.unstack().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1, figsize=(8,5))\n",
    "g1 = sns.barplot(x='sensor', y=0, data=df.loc[df['behavior'] == 'DLCwiggles'], ci=95, errwidth=0.75, capsize=0.05, palette='magma', ax = ax1)\n",
    "ax1.set_title('Duration of DLC Wiggles')\n",
    "ax1.set_ylabel('Duration (s)')\n",
    "\n",
    "fig, ax2 = plt.subplots(1, figsize=(8,5))\n",
    "g2 = sns.barplot(x='sensor', y=0, data=df.loc[df['behavior'] == 'manualsleep'], ci=95, errwidth=0.75, capsize=0.05, palette='magma', ax = ax2)\n",
    "ax2.set_title('Duration of Manual Immobility')\n",
    "ax2.set_ylabel('Duration (s)')\n",
    "\n",
    "fig, ax3 = plt.subplots(1, figsize=(8,5))\n",
    "g3 = sns.barplot(x='sensor', y=0, data=df.loc[df['behavior'] == 'DLCsleep'], ci=95, errwidth=0.75, capsize=0.05, palette='magma', ax = ax3)\n",
    "ax3.set_title('Duration of DLC Immobility')\n",
    "ax3.set_ylabel('Duration (s)')\n",
    "\n",
    "fig, ax4 = plt.subplots(1, figsize=(8,5))\n",
    "g4 = sns.barplot(x='sensor', y=0, data=df.loc[df['behavior'] == 'meal'], ci=95, errwidth=0.75, capsize=0.05, palette='magma', ax = ax4)\n",
    "ax4.set_title('Duration of Meal')\n",
    "ax4.set_ylabel('Duration (s)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check mean velocity per recording \n",
    "FL_behaviors = {'speed': []}\n",
    "ECD_behaviors = {'speed': []}\n",
    "ECDControl_behaviors = {'speed': []}\n",
    "ECD13A_behaviors = {'speed': []}\n",
    "ECD14C_behaviors = {'speed': []}\n",
    "\n",
    "for path in FL:\n",
    "    print(path)\n",
    "    temp = pd.read_hdf(f'{path}/dlcanalysis.h5')\n",
    "    temp = temp['tip_of_head', 'avg'][::10]\n",
    "    FL_behaviors['speed'] += [temp.mean()]\n",
    "dfFL = pd.DataFrame({k:pd.Series(v) for k,v in FL_behaviors.items()})\n",
    "\n",
    "for path in ECD:\n",
    "    print(path)\n",
    "    temp = pd.read_hdf(f'{path}/dlcanalysis.h5')\n",
    "    temp = temp['tip_of_head', 'avg'][::10]\n",
    "    ECD_behaviors['speed'] += [temp.mean()]\n",
    "dfECD = pd.DataFrame({k:pd.Series(v) for k,v in ECD_behaviors.items()})\n",
    "\n",
    "for path in ECD13A:\n",
    "    print(path)\n",
    "    temp = pd.read_hdf(f'{path}/dlcanalysis.h5')\n",
    "    temp = temp['tip_of_head', 'avg'][::10]\n",
    "    ECD13A_behaviors['speed'] += [temp.mean()]\n",
    "dfECD13A = pd.DataFrame({k:pd.Series(v) for k,v in ECD13A_behaviors.items()})\n",
    "\n",
    "\n",
    "for path in ECDControl:\n",
    "    print(path)\n",
    "    temp = pd.read_hdf(f'{path}/dlcanalysis.h5')\n",
    "    temp = temp['tip_of_head', 'avg'][::10]\n",
    "    ECDControl_behaviors['speed'] += [temp.mean()]\n",
    "dfECDControl = pd.DataFrame({k:pd.Series(v) for k,v in ECDControl_behaviors.items()})\n",
    "\n",
    "'''\n",
    "for path in ECD14C:\n",
    "    print(path)\n",
    "    temp = pd.read_hdf(f'{path}/dlcanalysis.h5')\n",
    "    temp = temp['tip_of_head', 'avg'][::10]\n",
    "    ECD14C_behaviors['speed'] += [temp.mean()]\n",
    "dfECD14C = pd.DataFrame({k:pd.Series(v) for k,v in ECD14C_behaviors.items()})\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FL_desc = dfFL.describe().loc[['mean', 'count'], :]\n",
    "FL_sem = pd.DataFrame(dfFL.sem(axis=0)).rename(columns={0: 'sem'}).T\n",
    "FL_desc = FL_desc.append(FL_sem).T.reset_index().rename(columns={'index': 'characteristic'})\n",
    "FL_desc['sensor'] = 'FL'\n",
    "\n",
    "ECD_desc = dfECD.describe().loc[['mean', 'count'], :]\n",
    "ECD_sem = pd.DataFrame(dfECD.sem(axis=0)).rename(columns={0: 'sem'}).T\n",
    "ECD_desc = ECD_desc.append(ECD_sem).T.reset_index().rename(columns={'index': 'characteristic'})\n",
    "ECD_desc['sensor'] = 'ECD'\n",
    "\n",
    "ECDControl_desc = dfECDControl.describe().loc[['mean', 'count'], :]\n",
    "ECDControl_sem = pd.DataFrame(dfECDControl.sem(axis=0)).rename(columns={0: 'sem'}).T\n",
    "ECDControl_desc = ECDControl_desc.append(ECDControl_sem).T.reset_index().rename(columns={'index': 'characteristic'})\n",
    "ECDControl_desc['sensor'] = 'ECD Control'\n",
    "\n",
    "\n",
    "ECD13A_desc = dfECD13A.describe().loc[['mean', 'count'], :]\n",
    "if ECD13A_desc.loc['count'][0] == 1:\n",
    "    ECD13A_desc = ECD13A_desc.T.reset_index().rename(columns={'index': 'characteristic'})\n",
    "    ECD13A_desc['sem'] = 0\n",
    "else:\n",
    "    ECD13A_sem = pd.DataFrame(dfECD13A.sem(axis=0)).rename(columns={0: 'sem'}).T\n",
    "    ECD13A_desc = ECD13A_desc.append(ECD13A_sem).T.reset_index().rename(columns={'index': 'characteristic'})\n",
    "ECD13A_desc['sensor'] = 'ECD 1.3a'\n",
    "\n",
    "'''\n",
    "ECD14C_desc = dfECD14C.describe().loc[['mean', 'count'], :]\n",
    "if ECD14C_desc.loc['count'][0] == 1:\n",
    "    ECD14C_desc = ECD14C_desc.T.reset_index().rename(columns={'index': 'characteristic'})\n",
    "    ECD14C_desc['sem'] = 0\n",
    "else:\n",
    "    ECD14C_sem = pd.DataFrame(dfECD14C.sem(axis=0)).rename(columns={0: 'sem'}).T\n",
    "    ECD14C_desc = ECD14C_desc.append(ECD14C_sem).T.reset_index().rename(columns={'index': 'characteristic'})\n",
    "ECD14C_desc['sensor'] = 'ECD 1.4c'\n",
    "'''\n",
    "\n",
    "\n",
    "combined_df = pd.concat([FL_desc, ECDControl_desc, ECD_desc, ECD13A_desc])#, ECD14C_desc])\n",
    "combined_data = combined_df.pivot(index='characteristic', columns='sensor', values='mean')\n",
    "combined_err = combined_df.pivot(index='characteristic', columns='sensor', values='sem')\n",
    "\n",
    "#fig, ax = plt.subplots(1, figsize=(8,5))\n",
    "#combineddata.plot(kind='bar', yerr=combinederr, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = ['FL', 'ECD', 'ECD Control', 'ECD 1.3a']\n",
    "#['WT FL', 'WT ECD', 'ECD 1.4a', 'ECD 1.4b', 'ECD 1.4c']\n",
    "speed_data = combined_data.loc[['speed']].reindex(columns=order)\n",
    "speed_err = combined_err.loc[['speed']].reindex(columns=order)\n",
    "\n",
    "\n",
    "fig, ax1 = plt.subplots(1, figsize=(8,5)) #dpi=1200 for final save \n",
    "speed_data.plot(kind='bar', yerr=speed_err, ax=ax1, legend=False, rot=0,\n",
    "               error_kw=dict(capsize=4, capthick=1), color=['white', 'lightgrey', 'darkgrey', 'gray', 'dimgray'], edgecolor='black')\n",
    "ax1.spines.right.set_visible(False)\n",
    "ax1.spines.top.set_visible(False)\n",
    "ax1.yaxis.set_ticks_position('left')\n",
    "ax1.xaxis.set_ticks_position('bottom')\n",
    "ax1.set_xticklabels('')\n",
    "ax1.set_ylabel('Average Speed Per Recording (cm/s)', fontsize=12)\n",
    "ax1.set_xlabel('Sensor Variant', fontsize=12)\n",
    "\n",
    "hl_list = [handle_label for handle_label in ax1.get_legend_handles_labels()]\n",
    "newlabel_list = []\n",
    "for label in hl_list[1]:\n",
    "    n_val = combined_df.loc[(combined_df['sensor'] == label) & (combined_df['characteristic'] == 'speed')]['count']\n",
    "    n_val = int(n_val)\n",
    "    newlabel_list.append(f'{label}, n={n_val}')\n",
    "hl_list[1] = newlabel_list\n",
    "ax1.legend(handles=hl_list[0], labels=hl_list[1], loc='center left', bbox_to_anchor=(1, 0.5), frameon=False, handlelength=1, handleheight=1, edgecolor=None)\n",
    "\n",
    "fig.subplots_adjust(right=0.7)\n",
    "plt.savefig('AverageSpeeds_NewerVariants.pdf', format='pdf', dpi=1200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
